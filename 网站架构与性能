====带宽
摘自: http://www.biphp.com/websitedesign/%E8%AF%A6%E8%A7%A3%E5%A6%82%E4%BD%95%E6%A0%B9%E6%8D%AE%E7%BD%91%E7%AB%99pv%E9%80%89%E6%8B%A9%E4%B8%BB%E6%9C%BA%E5%B8%A6%E5%AE%BD/

网站PV（page view，即页面浏览量或点击量）

通常所讲的1M带宽指1Mbps，1Mbps=1024K bit per sec=128K Byte per sec，也就是128KB/秒，不要理解成1MB/秒。网站服务器有1M带宽，那么下载速度最高128KB/秒。

共享带宽还是独享带宽

使用双线，多线的主机比单线的主机好，可以兼容电信、联通、教育网等不同网络服务商。双线、多线的价格比单线要贵一些。

阿里云服务器的带宽都是独享多线带宽，在购买时或使用中，可以根据需要，在初始带宽的基础上增加带宽，增加1M带宽需100元/月。

一般来讲8:00-23:00为忙时访问人数较多，假设占日PV的90%，其它时段为闲时占日PV的10%
其中忙时又可以根据访问情况再细分为不同时段。这里假设忙时15小时中的5小时占日PV的45%，其余10小时占日PV的45%.


绵阳主机: 10M独享

网站流量（traffic）就是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的网页数量等指标，
常用的统计指标包括网站的独立用户数量、总用户数量（含重复访问者）、网页浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。

网站访问量的衡量标准一个是IP,另一个是PV,常以日为标准,即日独立IP和PV来计算.

    访问数（IP）：即Internet Protocol,指独立IP数。00:00-24:00内相同IP地址只被计算一次。
    综合浏览量（PV）：即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次。

CDN 的全称是Content Delivery Network，即内容分发网络。其目的是通过在现有的互联网中增加一层新的网络架构，将网站的内容发布到最 接近用户的网络“边缘”，使用户可以就近取得所需的内容，分散服务器的压力

使用CDN技术的域名解析服务器需要维护一个镜像服务器列表和一份来访IP到镜像服务器的对应表。当一个用户的请求到来的时候，根据用户的 IP，查询对应表，得到最优的镜像服务器的IP地址，返回给用户



带宽计算结果:
10000PV  20000PV
0.35Mb   0.70Mb    移动门户
0.44Mb   0.88Mb    校园社区 

阿里云推荐配置:
    标准B型 	2核Xeon 2.26GHz(CPU) 	2.5GB(MEM) 	230GB(DISK)  5Mbps(带宽) 	
    总费用: 500元(月费) 	5000元(年费)

盛大云推荐配置:
    云主机套餐标准型  2core/4G/60G  440元(月费) 4400(年费)
    5Mbps(双线带宽)  360元(月费)  3720(年费) 
    总费用: 800元(月费)   8120(年费) 


简单的道理: 
    索引优于没有索引
    内存优于磁盘
    近距离优于远距离


安装基线测试工具:
    sudo apt-get install apache2-utils

====分布式缓存
城市道路的十字路口,它就像一个写缓冲区,红灯亮起的时候,车辆都停在缓冲区,当变成绿灯后,车辆开始依次前进,这就像内核缓冲区中的数据
积累到一定程度时被写入磁盘。

# memcached -d -m 4086 -l 10.0.1.12 -p 11711
TCP Socket访问
memcached 使用 libevent 函数库来实现网络并发模型
两个评测指标: 
    每秒处理请求数
    每秒set次数(每秒处理能力)

memcached将一个类的对象(或类的实例)进行序列化时,对象的成员函数是不被序列化的,而被序列化存储的只是对象的数据成员。
反序例化:
    首先会实例化一个新的对象,然后将之前持久化的数据成员依次赋值给新对象的相应数据成员。
MySQL查询分析器: 分析SQL执行性能
    mysql> explain select * from auth_user where id=1;
    +----+-------------+-----------+-------+---------------+---------+---------+-------+------+-------+
    | id | select_type | table     | type  | possible_keys | key     | key_len | ref   | rows | Extra |
    +----+-------------+-----------+-------+---------------+---------+---------+-------+------+-------+
    |  1 | SIMPLE      | auth_user | const | PRIMARY       | PRIMARY | 4       | const |    1 |       |
    +----+-------------+-----------+-------+---------------+---------+---------+-------+------+-------+
    1 row in set (0.01 sec)

    -----此次查询利用了该索引,直接找到目标,的确,rows 为 1

吞吐率提高了大约 58%,因为我们使用了数据库的“前置读缓存”。事实上,数据库本身也有查询缓存.

站点访问量统计功能:
    需要记录每个 URL 的累计访问量,所以每次页面刷新都会伴随着一次访问量的增加,将访问量数据保存在数据库中
   ---加入memcached写缓存,数据更新出现延迟,但是我们可以接受.从缓存服务器上取回一个数值,然后在本地加 1,接下来写回缓存服务器。锁竞争,原子加法.
改变了之前的“直接更新”方式,当需要增加一次访问量的时候,它做了以下工作:
    1.为 memcached 缓存中的对应数据项加 1,如果该数据项不存在,则创建该数据项,并且赋值为 1,代表这个页面是第一次被访问;
    2.如果 memcached 缓存中存在对应数据项,并且累加后的数值为 1000,则将这个数据项置 0,同时更新数据库,将数据库中的对应数值加 1000。
    改造后的程序每经历1000次递增后才写一次数据库, 吞吐率提高了大约46%.
如果你的数据库因为大量的写操作而繁忙不堪,那么仔细考虑一下,哪些写操作可以缓存在 memcached 中呢?

分布式缓存系统的状态监控:(cacti监控系统监控memcached使用率)
    空间使用率:(有助何时需要为缓存扩容)
    命中率
    I/O流量:

缓存扩展:　通过增加新的缓存服务器.
当存在多台缓存服务器时,如何将缓存数据均衡分布到多台缓存服务器.

====Ｗeb负载均衡
作为架构师的你,从一开始就要思考未来的扩展计划,并且为扩展而进行架构设计,但是关键在于,你必须能够意识到何时需要实施扩展,并且有足够的数据来证明这种必要性。

可扩展性,实际上是指系统通过扩展规模来提升承载能力的本领.
对于Ｗeb的水平扩展,　负载均衡是一个常见手段.
应该尽量避免单点故障,最优化任务分配的问题.

HTTP重定向作用:
    １.请求转移和自动跳转
    ２.实现负载均衡,以达到Web扩展的目的

通过不同的地域来源来转移请求只是负载均衡的一种策略.在网络I/O成为主要瓶颈(比如下载服务)的时候,这种
策略的优势表现得尤为突出。

==重定向的性能和扩展能力
    主站点负责转移请求(master)
    其他服务器负责实际处理请求(slave)

    假设这三台实际服务器的首页能承受的最大吞吐率为500reqs/s,那么理论上当主站点的实际吞吐率小于1500reqs/s 
的时,实际服务器可以在承受范围内提供服务。当主站点的实际吞吐率大于 1500reqs/s 后,我们便需要增加实际服务器,
但是理论上最多可以增加到13台,这取决于主站点首页的最大吞吐率(6438.46reqs/s),它几乎是实际服务器上首页最大吞
吐率的13 倍。


ab -n 1000 -c 100 http://www.google.com/  ---ab使用, 向google.com发送1000个请求，每次100个


大多数情况下通过重定向来实现整个站点的负载均衡,并不那么让人满意。

反向代理是常用方法，由HTTP Server完成。

＝＝文件下载的重定向(负载均衡)
对于文件下载、广告展示等一次性的请求,主站点调度程序可以牢牢地把握控制权,实际服务器的 URL 甚至可以
含蓄地隐藏起来,与此同时,这种一次性的请求,也比较容易让多台实际服务器保持均衡的负载,但是也必须考虑一些现实
的问题,比如分配给不同实际服务器下载的文件可能尺寸差异较大,我们需要在次数分配均衡的情况尽量保证文件尺寸分配
均衡,也就是带宽使用分配均衡,这也许需要借助于应用程序,你可以记录下给每个实际服务器派发的下载文件的尺寸,从
而在每次下载转移前挑选你认为比较轻松的实际服务器

==负载反馈
让主站点的定时任务不断获取每个实际服务器的实时流量,这可以通过 SNMP获得原始数据并计算得出,这些数据将作为下载转移的权重参考.也许你觉得在请求转移逻辑中加入各实际服务器流量权重
分析会带来额外的开销,但是,相比于下载的时间开销而言,这些额外的开销实在是九牛一毛。

权衡:转移请求的开销和处理实际请求的开销.

====DNS负载均衡
Ａ记录:DNS基本功能, 映射域名<--->IP地址
常用DNS系统: Linux bind, Windows DNS服务,都支持一个域名指定多个IP地址.

dig baidu.com  --出现3个A记录,对应3个IP地址
ping baidu.com --连续3次ping,会出现3个IP地址

说明: DNS 服务器使用三个不同的 IP 地址来轮流解析 baidu.com 域名,实现了RR调度策略.

DNS 负载均衡的实现主要依赖于 DNS 服务器的设置,如果你的站点拥有自己的 DNS 服务器,那么以上的设置对于
DNS 管理员来说并不困难.但是,大多数站点仍然使用第三方 DNS 服务商,幸运的是,现在有很多 DNS 服务商完全支持多个 A 记录的轮询设置,你可以根据需要来挑选。

作为调度器,DNS 服务器本身的性能我们几乎不用担心. DNS 记录可以被用户浏览器或者互联网接入服务商的
各级 DNS 服务器缓存,只有当缓存过期后才会重新向该域名的 DNS 服务器请求解析.
一般会配备至少两台以上的 DNS 服务器来提高可用性

当你不必为扩展担忧的时候,另一方面的问题便开始暴露, 如何管理这么多的服务器呢?诸如内容同步、数据共享、状态监控等

负载均衡方式: 
    HTTP重定向负载均衡: 受到主站点性能制约, 但调度策略具有好的灵活性, 可通过Web应用程序实现.
    DNS负载均衡: 但为DNS服务器开发自定义的调度策略不那么容易. DNS服务器可在所有可用的A记录中寻找
            离用户最近的一台服务器.
    反向代理负载均衡:
    硬件层面的负载均衡

当然,如何利用这种策略,完全取决于你,你可以为用户比较集中的一些城市提供专用的服务器,接入城市核心节点,也可
以为各互联网运营商网络中的用户提供专用的服务器,并接入该运营商骨干节点,要做到这些,你还需要收集到相应的网络
地址分布数据,并添加到 DNS 服务器的智能解析策略中。

DNS就近解析策略

TTL：(Time To Live ) 生存时间
指定数据包被路由器丢弃之前允许通过的网段数量。 TTL 是由发送主机设置的，以防止数据包不断在IP互联网络上永不终止地循环。转发 IP数据包时，要求路由器至少将 TTL 减小 1。 

动态域名解析
当你的主机使用动态 IP 地址接入互联网,并且你希望将某个域名指向这台主机时, 动态域名解析便发挥了作用
在每次 IP 地址变更时及时地更新 DNS 服务器,当然,一定的延迟仍然是在所难免的,同样是因为 DNS 记录的 TTL
利用同样的思路,当我们监测到某台实际服务器发生故障后,便可以通过动态 DNS 协议来迅速修改 DNS 记录.

DNS 服务器充当了一个粗放型的请求调度器
RR 调度: 时间片轮转(round-robin)

====反向代理负载均衡
核心就是转发HTTP请求.
HTTP 重定向和 DNS 解析,体现在"转移"上, 反向代理负载均衡体现在“转发”上.

==Nginx作为反向代理服务器
10.0.1.50 的服务器上运行 Nginx, 配置两个后端服务器,如下:
    upstream backend {
        server 10.0.1.200:80;
        server 10.0.1.201:80;
    }

服务器用途           内部网络 IP      外部网络 IP
反向代理服务器        10.0.1.50       125.12.12.12
后端服务器            10.0.1.210         -
后端服务器            10.0.1.201         -



反向代理服务器进行转发操作本身是需要一定开销的,比如创建线程、与后端服务器
建立 TCP 连接、接收后端服务器返回的处理结果、分析 HTTP 头信息、用户空间和内核空间的频繁切换等,通常这部分时间并不长,但是当后端服务器处理请求的时间非常短时,转发的开销就显得尤为突出。

工作在 HTTP 层面的反向代理服务器扩展能力的制约,不仅来自于自身的对外服务能力,也归咎于其
转发开销是否上升为主要时间。

当采用 RR 调度策略时,即便是同一用户对同一内容的多次请求,也可能被转发到了不同的后端服务器,带来的问题:
    当某台后端服务器启用了 Session 来本地化保存用户的一些数据后,下次用户的请求如果转发给了其他后端服务器,将导致之前的 Session 数据无法访问;
    后端服务器实现了一定的动态内容缓存,而毫无规律的转发使得这些缓存的利用率下降。

从表面上看,我们需要做的就是调整调度策略,让用户在一次会话周期内的所有请求始终转发到一台
特定的后端服务器上,这种机制也称为粘滞会话(Sticky Sessions),要实现它的关键在于如何设计持续性调度算法。

要让调度器可以识别用户,那么将用户的 IP 地址作为识别标志最为合适.
将用户的 IP 地址进行 Hash 计算并散列到不同的后端服务器上。
还可以利用 Cookies 机制来设计持久性算法,比如调度器将某个后端服务器的编号追加到写给用户的 Cookies.
调度器便可以在该用户随后的请求中知道应该转发给哪台后端服务器。这样做可以更加细粒度地追踪到每一个用户
当有很多用户隐藏在一个公开 IP 地址后面时,利用 Cookies 的持久性算法将显得更加有效

粘滞会话可能或多或少地破坏了均衡策略.
问题的关键在于,我们究竟是否要通过实现粘滞会话来迁就系统的特殊需要呢?在权衡代价之后你认为是否值得呢?

====*****====
在后端服务器上保存 Session 数据和本地化缓存,的确是一件不明智的事情,它使得后端服务器显得过于个性化,以
至于和整个系统格格不入,如果允许的话,我们应该尽量避免这样的设计,比如采用分布式 Session 或者分布式缓存等,让后端服务器的应用尽量与本地无关,也可更好地适应环境。

iptables实现调整:
iptables -F INPUT
iptables -A INPUT -i eth0 -p tcp --dport 80 -j ACCEPT
iptables -P INPUT DROP
    --告诉内核只允许外部网络通过 TCP 与这台服务器的 80 端口建立连接
用 iptables 来实现本机端口重定向,比如以下的规则:
    iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8000

NAT反向代理:
对于一些开销较大的内容,使用简单的反向代理来搭建负载均衡系统是非常值得考虑的,至少在初期是一个快速有效的方案,而且它可以非常容易地迁移到 NAT 方式.

如果条件允许,你也可以购买专业级的负载均衡硬件产品,比如 Cisco 的 LocalDirector 或 F5 的 BIG-IP Local TrafficManager,它们都可以实现基于 NAT 的负载均衡,并且支持丰富的调度策略,它们可以达到较高级别的带宽,而且拥有强大的管理功能,但价格不菲.

p60...


垂直分区: 比如我们将用户的博客数据库和好友数据库分别转移到独立的数据库服务器上.


很多大规模的站点基本上都经历了从简单主从复制(读写分离)到垂直分区(功能与业务层面分库),再到水平分区(将同一个表中数据分割)的步骤
水平分区并不依赖于特定的技术,它更多的是一种逻辑层面的规划,需要一定的经验和不断的分析。

分表只是单台数据库的优化策略,一旦到了必须考虑扩展的时候,分区便派上用场.
在大多数时候,对哪些数据进行分区并不是我们可以选择的,对于那些频繁访问而导致站点接近崩溃的热点数据,我们没有理由不对它们考虑分区
一旦我们知道要对哪些数据实施分区后,接下来就得找到一个用于分区的字段,我们称为分区索引字段,比如前面的 user_id,它必须和所有的记录都存在关系,一般我们会用被分区数据的主键或者外键

分表算法和分区算法可能不一致,比如我们希望将这 10 个表分布在两台服务器上,那么我们要在应用程序中维护
一份映射关系表,比如将前 5 个数据表分配到一台数据库服务器,后 5 个数据表分配到另一台数据库服务器

在我们不得不对一些数据进行分区的时候,也意味着我们将失去一些操作它们的能力,比如原本你可以通过一条联合
查询语句就能轻松搞定的任务,在分区后,你必须先通过用户 ID 找到正确的分区,然后查到对应的好友 ID,再通过好友 ID
找到对应的分区,从而找到好友信息。但是,你也不必感到沮丧,曾经的联合查询将会随着站点规则的增大变得越来越昂贵,
而分区后的查询方式将会更加容易保持相对稳定的开销。

一旦我们知道要对哪些数据实施分区后,接下来就得找到一个用于分区的字段,我们称为分区索引字段,比如前面的 user_id

分区算法:
    哈希算法: 比如通过 user_id%10 来实现分区便是这种算法
    范围: 比如我们可以将 user_id 为 1~10000 的记录存储在一个分区中,而将10001~20000 的用户存储在另一个分区中
    映射关系:
        对分区索引字段的每个可能的结果创建一个分区映射关系,这个映射关系将会非常庞大.
        比如当应用程序需要知道 user_id 为 10 的用户的博客内容在哪个分区时,它必须查询数据库获得答案,当然,我们会使用缓存来提高性能。

分区反向代理: 
    MySQL Proxy帮助应用程序实现了读写分离
    Spock Proxy 可以帮助应用程序实现水平分区的访问调度

    
====性能优化经验 (http://www.williamlong.info/archives/1960.html)
经验是从数据开始，从最外围开始画圈，找到源头。
先从外围开始收集日志，比如access_log访问日志或sql_log数据库操作日志，找出访问最多的10条日志和执行时间最长的10条日志，
然后根据日志去反查到底是什么引起的操作，然后一条条的解决。从经验来看，往往就是因为几个功能点的恶化，引起了整体的性能变差。

====
动静分离
为静态媒体分出专门的子域名如static.domain.com来提供服务

缓存失效
要避免缓存实效，可以依赖于数据库缓存，或者为缓存数据添加有效期，又或者在实现应用程序逻辑时，尽量考虑避免此问题。例如不直接使用DELETE FROM a WHERE…来删除数据，而是先查询符合条件的数据，再使得缓存中对应的数据失效，继而根据其主键显式地删除这些行。

基于消息的分布式架构:
    http://agiledon.github.io/blog/2012/12/27/distributed-architecture-based-on-message/
    引入Message Queue，可以极大地缓解Web服务器的压力，因为它可以将耗时较长的任务转到专门的机器上去执行。

通过引入定时任务，也可以有效地利用Web服务器的空闲时间来处理后台任务。
大数据的处理，自然可以引入Map-Reduce.

在这样一个独立的物理分层架构中，不同层次对服务器的要求是不一样的。例如:
    1.对于数据库服务器而言，由于需要频繁地对磁盘进行I/O操作，因此应保证数据库服务器的IO性能，如尽量使用固态硬盘。
    2.对于Web服务器而言，则对CPU的要求比较高，尽可能采用多核CPU。

====豆瓣经验
数据备份到本地
数据库的内存分配对性能影响重大 • innodb_buffer_pool_size
磁盘随机寻道速度比吞吐量更重要
网上找来的IP段分布很不靠谱

数据库的主从备份:
    多slave上进行数据挖掘(更多读取操作), 挖掘计算结果写回到master
memcache并不廉价,仔细控制cache的对象大小和访问方式
避免数据库的join操作
在产品上做出限制以避免过慢的查询

团队09年
    11人=全+兼
    5人=算法团队

更新数据到master(主DB), 预计马上会用到, 则同时更新cache以便能访问到最新数据.
InnoDB自我管理缓存
所有的静态内容(js/css/img/media等)使用二级域名
    LVS 是一个开源的软件，可以实现LINUX平台下的简单负载均衡。
    LVS集群采用IP负载均衡技术和基于内容请求分发技术。调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。为此，
    LVS主要组成: 负载调度器,服务器池,共享存储






























































