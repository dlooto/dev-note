NOSQL--

===memcached, redis 比较

没有必要过多的关心性能，因为二者的性能都已经足够高了。由于Redis只使用单核，而Memcached可以使用多核，
所以在比较上，平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要
高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。说了这么多，结论是，
无论你使用哪一个，每秒处理请求的次数都不会成为瓶颈。（比如瓶颈可能会在网卡）

如果要说内存使用效率，使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，
由于其组合式的压缩，其内存利用率会高于Memcached。当然，这和你的应用场景和数据特性有关。

如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis，因为这两个特性Memcached都不具备。即使你只是希望
在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。

当然，最后还得说到你的具体应用需求。Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，
通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。
在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果你需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。
来源：Is memcached a dinosaur in comparison to Redis?


======memcached最佳实践
　　但是也不太建议在任何情况下使用Memcached替代任何缓存：

　　1） 如果Value特别大，不太适合。因为在默认编译下Memcached只支持1M的Value（Key的限制到不是最大的问题）。其实从实践的角度来说也不建议把非常大的数据保存在Memcached中，因为有序列化反序列化的过程，别小看它消耗的CPU。说到这个就要提一下，我一直觉得Memcached适合面向输出的内容缓存，而不是面向处理的数据缓存，也就是不太适合把大块数据放进去拿出来处理之后再放进去，而是适合拿出来就直接给输出了，或是拿出来不需要处理直接用。

　　2） 如果不允许过期，不太适合。Memcached在默认情况下最大30天过期，而且在内存达到使用限制后它也会回收最少使用的数据。因此，如果我们要把它当作static变量的话就要考虑到这个问题，必须有重新初始化数据的过程。其实应该这么想，既然是缓存就是拿到了存起来，如果没有必定有一个重新获取重新缓存的过程，而不是想着它永远存在。


　　在使用Memcached的过程中当然也会有一些问题或者说最佳实践：

　　1） 清除部分数据的问题。Memcached只是一个Key/Value的池，一个公共汽车谁都可以上。我觉得对于类似的公共资源，如果用的人都按照自己的规则来的话很容易出现问题。因此，最好在Key值的规范上上使用类似命名空间的概念， 每一个用户都能很明确的知道某一块功能的Key的范围，或者说前缀。带来的好处是我们如果需要清空的话可以根据这个规范找到我们自己的一批Key然后再去清空，而不是清空所有的。当然有人是采用版本升级的概念，老的Key就让它过去吧，到时候自然会清空，这也是一种办法。不过Key有规范总是有好处的，在统计上也方便一点。

　　2） Value的组织问题。也就是说我们存的数据的粒度，比如要保存一个列表，是一个保存在一个键值还是统一保存为一个键值，这取决于业务。如果粒度很小的话最好是在获取的时候能批量获取，在保存的时候也能批量保存。对于跨网络的调用次数越少越好，可以想一下，如果一个页面需要输出100行数据，每一个数据都需要获取一次，一个页面进行上百次连接这个性能会不会成问题。

　　那么Memcached主要用在哪些功能上呢？

　　其实我觉得平时能想到在内存中做缓存的地方我们都可以考虑下是不是可以去适用分布式缓存，但是主要的用途还是用来在前端或中部挡一下读的需求来释放Web服务器App服务器以及DB的压力。


MongoDB的设计是要结合键值存储和关系型数据库的最好特性。键值存储，因为非常简单，所以速度极快而且相对容易伸缩。
关系型数据库较难伸缩，至少很难水平伸缩，但拥有富数据模型和强大的查询语言。如果MongoDB能介于两者之间，就能成为一款易伸缩、能存储丰富数据结构、提供复杂查询机制的数据库。


=====
存储媒体文件，可以考虑用 mongo gridfs 
那比如你一个 1u的服务器，能放 6T ，放满了的时候，你在加服务器怎么办？ 
又得去改代码，重新配置新服务器 
而用 gridfs ，只需要简单的配置 mongo 的分片就是，扩容完全不需要改代码得 
图片的元数据都直接用 gridfs 存储了 
从我目前了解的来看，数据增长不是很大的，或数据之意关系比较强的，比如帐户数据，可以用 MySQL；而其它弱关系的，比如图片文件和社交数据等，就用MongoDB 

===消息队列
比如新浪微博，你有1000万个粉丝，你post 一条微博，要通知所有的粉丝，你发新微博了。
你就可以把通知交给mq去排队发送。服务器速度快点就早点通知对方，慢点儿就晚点通知对方。
你就不需要在 app server 弄个线程来发噻.
反正这种通知又不需要太强的急时性.

消息队列:
    zeromq(C/C++开发),
    用 RabbitMQ , activemq 的公司可能比较多 
    amqp 是 MQ 的标准协议 

======张冬实现注册邮件发送的方式
把邮件信息全部放到一表中
用别外一个进程慢慢的去读，去发, 还不会存在丢失的问题.开进程是为了防止当前的进程堵或者其它原因，而且还可以多机器.
初始可以考虑开一个线程来处理.
该进程一直开启,无邮件可发时sleep几秒.
发完了, DB里的数据可不用删掉, 修改一个状态就好了, 删除其实挺浪费时间的, 如果实在没空间不够，定期删除也行.  

另外一场景: 我发了一条微博, 关注我的人都会收到一个提醒消息. 这个应该用消息队列更可行
    两种情况:推与拉
    关注者多就拉, 少就推

Dlooto2012-12-06 14:43:53	
    一个人的关注者, 一开始很少, 后来会增加, 初始用推, 后面再改成拉? 代码后期得改?
张冬2012-12-06 14:44:45	
    在准备的时候取一下关注者数嘛 


pip install python-memcached

====to cache template fragments
{% load cache %}
{% cache 500 sidebar %}
    .. sidebar ..
{% endcache %}

===cache view
urlpatterns = ('',
    (r'^foo/(\d{1,2})/$', cache_page(60 * 15)(my_view)),
)

from django.views.decorators.cache import cache_page

@cache_page(60 * 15, key_prefix="site1")
def my_view(request):
    ...

===cache API
>>> from django.core.cache import cache

如果有多个cache定义在CACHES中,可以用get_cache()通过key 检索cache object。
>>> from django.core.cache import get_cache
>>> cache = get_cache('alternate')

>>> cache.set('my_key', 'hello, world!', 30)   --超时时间
>>> cache.get('my_key')
'hello, world!'

>>> cache.set_many({'a': 1, 'b': 2, 'c': 3})
>>> cache.get_many(['a', 'b', 'c'])
{'a': 1, 'b': 2, 'c': 3}

>>> cache.delete('a')

>>> cache.delete_many(['a', 'b', 'c'])

clear() will remove everything from the cache, not just the keys set by your application.
cache.clear()


